%!TEX root = ./template-skripsi.tex
%-------------------------------------------------------------------------------
%                     BAB III
%               			PEMBAHASAN
%-------------------------------------------------------------------------------

\chapter{METODOLOGI PENELITIAN}

\section{Tahapan Penelitian}

Gambar \textit{flowchart} berikut mengilustrasikan proses pelatihan 
 dari dataset dan juga proses penggunaan yang sesungguhnya.

\begin{figure}[H]
  \centering{}
	\includegraphics[width=0.6\textwidth]{gambar/flowchart\_1\_1}
  \caption{Diagram alir untuk algoritma pelatihan klasifikasi objek}
\end{figure}

\begin{figure}[H]
  \centering{}
	\includegraphics[width=0.6\textwidth]{gambar/flowchart\_2}
  \caption{Diagram alir untuk algoritma pendeteksian objek}
\end{figure}

%(Jelasin disini secara ringkas, biar gak terlalu ambigu)

\section{Desain Sistem}

Dalam proses pembuatan \emph{classifier} perlu dilewati tahapan \textit{training}. 
Tujuan \textit{training} adalah untuk menciptakan suatu \emph{strong classifier} 
yang nantinya dapat digunakan untuk melakukan klasifikasi yang sebenarnya.
Pertama, gambar yang akan menjadi contoh pelatihan dianotasi sesuai kelasnya masing-masing dengan 
memberikan label yang sesuai dengan kelas mereka masing-masing, 
contoh latihan ini berisikan gambar-gambar yang tidak memiliki kelas yang benar, atau 
\emph{false example} dan juga gambar-gambar yang memiliki kelas yang benar, atau 
\emph{positive example}. Setelah itu gambar melalui proses \emph{pre-processing} dan disesuaikan 
untuk mengoptimalkan proses pelatihan.

Pertama sebuah set \textit{features} akan dibuat dengan cara mencoba semua kemugnkinan 
yang ada dengan bentuk fitur yang dimiliki. Set ini akan berisikan informasi fitur-fitur 
yang nantinya akan dipakai untuk mendapatkan nilai fitur yang sesungguhnya. Set gambar latihan 
lalu akan dibaca menggunakan semua fitur ini dan hasilnya akan dicatat dalam tabel csv. 
Algoritma lalu akan mengkonstruksi sebuah \emph{decision tree} untuk setiap 
\emph{feature} untuk menentukan nilai \textit{feature threshold} setiap kelas. 
\emph{Decision tree} lalu akan di-\textit{boosting} untuk menentukan nilai bobot votingnya 
pada \textit{strong clossifier}. Akhrinya dari sekumpulan \emph{decision tree} ini dibuatlah 
sebuah \emph{final strong classifier} yang berbentuk \textit{cascade}.

Dengan \emph{final strong classifier}, barulah klasifikasi objek yang sesungguhnya dapat dilakukan. 
Pertama gambar yang akan dideteksi akan melalui \emph{pre-processing}. setiap sub-window akan dicek menggunakan 
\emph{strong classifier} untuk menentukan kelasnya. Hal ini dilakukan pada tiga area: area kiri untuk 
mengklasifikasi mulut dari ikan, area tengah untuk mengklasifikasi sirip dari ikan, dan terakhir area kanan 
untuk mengklasifikasi bentuk ekor dari ikan. Hasil ketiga \textit{sub-window} ini nantinya juga akan ber-\textit{voting}
dimana jika ada dua atau lebih \textit{sub window} berhasil mengklasifikasikan kelas yang sama, maka kelas itu 
dipilih sebagai kelas dari objek pada gambar. Kelas dari objek lalu akan dituliskan di pojok kiri atas gambar.

\section{Training \emph{Strong Classifier}}

Pada \textit{Training} ada tiga tahapan yang perlu dijalankan 
untuk menghasilkan sebuah \emph{Strong Classifier}, 
yaitu penginputan \textit{dataset} pelatihan yang sudah dianotasi, 
pembuatan \emph{features}, 
pembuatan \emph{decision tree} untuk setiap \emph{features}, 
\emph{Boosting }dan pemilihan fitur untuk pemebuatan \emph{attentional cascade}.

\subsection{\textit{Input Dataset} Pelatihan}

\begin{figure}[H]
  \centering{}
	\includegraphics[width=0.6\textwidth]{gambar/dataset\_2}
  \caption{Contoh gambar Abudefduf, Amphiprion, Chaetodon dan contoh gambar-gambar negatif}
\end{figure}

\textit{Dataset} yang akan dipakai diambil dari FishBase (Dapat dilihat di https://fishbase.mnhn.fr/) yang 
berisikan berbagai gambar ikan termasuk gambar dari spesies Abudefduf, gambar dari spesies 
Amphiprion dan gambar dari spesies Chaetodon. 
Ketiga spesies ikan ini dipilih karena bentuknya yang berbeda satu-sama lain. %Selain itu 
% \textit{dataset} juga akan ditambahkan dari hasil penelitian lapangan 
% secukupnya, dengan mempertimbangkan waktu komputasi pada tahap 
% pelatihan.
Untuk contoh pelatihan gambar dibuat berukuran 350x200 piksel, 
dengan warna \textit{greyscale}. Selain itu juga akan dipilih contoh 
pelatihan negatif atau kumpulan gambar yang tidak terdapat kelas 
ikan dari http://www.vision.caltech.edu/datasets/ dengan jumlah yang sama, resolusi sama dan perlakuan 
yang sama. Anotasi dilakukan dengan menyimpan label dalam sebuah \textit{array}, label 
diambil dari sumber folder gambar. Kelas 0 direservasi untuk kelas negatif, sementara kelas 
1, 2 dan 3 direservasi untuk Abudefduf, Amphiprion dan Chaetodon.
\textit{Dataset} ini lalu dibagi menjadi tiga yaitu \textit{training dataset}, 
\textit{testing dataset}, dan \emph{validation dataset} dengan jumlah yang sama.

Selain itu untuk setiap kelas sudah dibuatkan \textit{sub-window} spesifik untuk diklasifikasi. 
\textit{Sub-window} ini secara spesifik mengklasifikasi tiga bagian ikan yaitu, mulut, sirip dan ekor. 
klasifikasi spesifik ini nantinya akan bekerja-sama dengan \textit{sliding window} dalam mengklasfikasi 
gambar yang ada, dengan mencari mulut, sirip dan ekor ikan didalam gambar.

\begin{figure}[H]
  \centering{}
	\includegraphics[width=0.6\textwidth]{gambar/window\_compund}
  \caption{\textit{sub-window} setiap kelas ikan yang akan dipelajari oleh \textit{classifier}}
\end{figure}

\begin{algorithm}
  \caption{offset \textit{sub-window} untuk training setiap kelas}
  \begin{algorithmic}[1]
    \State $\text{{class\_Window\_offset\_1}} \gets$ [
      \Comment{For searching mouth features}
      (0, 0),
      (88, 0), 
      (73, 0),
      (100, 15)
    ]
    \State $\text{{class\_Window\_offset\_2}} \gets$ [
      \Comment{For searching fin features}
      (0, 0),
      (0, 116), 
      (9, 153),
      (0, 116)
    ]
    \State $\text{{class\_Window\_offset\_3}} \gets$ [
      \Comment{For searching tail features}
      (0, 0),
      (89, 280), 
      (47, 237),
      (80, 277)
    ]
  \end{algorithmic}
\end{algorithm}

% \subsection{Pembuatan \textit{Integral Image}}

% Untuk pembuatan \emph{Integral Image}, pertama perlu dicari nilai piksel
% baris pertama dan kolom pertama dari gambar. Nilai pada matriks \emph{Integral Image} 
% adalah median dari nilai RGB pada piksel tersebut, namun dikarenakan warna 
% gambar sudah dirubah menjadi \emph{greyscale} maka nilai pada setiap piksel 
% hanya akan berupa bilangan bulat dikisaran 0 sampai 255. Nilai pada kolom 
% pertama hanyalah penjumlahan nilai piksel dari piksel $(0, 0)$ sampai ke piksel 
% $(0, j)$, sementara nilai pada baris pertama juga hanya penjumlahan nilai 
% piksel dari $(0, 0)$ ke  $(i, 0)$. Nilai-nilai piksel lainnya lalu dapat 
% dihitung menggunakan rumus: 
% \begin{equation}
%   \begin{split}
%     \text{integral image } (i,j) = {} & \text{integral image } (i-1,j) + \text{integral image } (i,j-1) - \\
%     & \text{integral image } (i-1,j-1) + \text{nilai dari piksel } (i,j)
%   \end{split}
% \end{equation}
% Atau jumlah semua nilai piksel dari $(0, 0)$ sampai ke $(i, j)$.
% Pembuatan \emph{integral image} nantinya akan digunakan oleh fitur sebagai \textit{input}.

% \begin{figure}[H]
%   \centering{}
% 	\includegraphics[width=0.6\textwidth]{gambar/integral\_image\_3}
%   \caption{Gambaran \emph{integral image} dari gambar sebuah bidak catur.}
% \end{figure}

\subsection{Pembuatan \textit{Haar like Features}}

Fitur-fitur yang akan digunakan dalam klasifikasi dibuat 
berdasarkan \emph{Haar-like Features} dan berisikan informasi penting yang dapat digunakan 
untuk mencari nilai sebuah fitur. Sebuah fitur berisikan tipe fiturnya, lokasi fitur tersebut 
didalam \textit{sub-window}, dan ukuran dari fitur tersebut.
Misalnya ada sebuah fitur, ia bertipe dua persegi menghadap ke kiri, lokasi x-nya adalah 12 piksel, 
dan lokasi y-nya adalah 10 piksel, dia memiliki ukuran 8 x 8 piksel.

\begin{figure}[H]
  \centering{}
	\includegraphics[width=0.6\textwidth]{gambar/feature\_data\_1}
  \caption{Sebuah fitur dua persegi menghadap ke kiri, lokasi x = 12 piksel, 
  lokasi y = 10 piksel, dengan ukuran 8 x 8 piksel.}
\end{figure} 
Dengan informasi yang ada didalam sebuah fitur tersebut, nilai fitur dapat dicari dengan 
mudah menggunakan rumus:

\begin{equation}
  \begin{split}
    \sum \text{nilai piksel area putih} -  \sum \text{nilai piksel area hitam} \\ 
  \end{split}
\end{equation}

Pada tahap ini fitur yang dipilih akan dibuat untuk semua 
posibilitas lokasi yang ada dan ukuran yang ada. Hal ini dilakukan dengan 
membuat fitur dimulai dari kiri atas gambar dengan ukuran 2 x 2 piksel untuk fitur 
dua persegi, empat persegi dan diagonal. Dan fitur 1 x 3 piksel atau 3 x 1 piksel untuk 
fitur tiga persegi. Hal ini juga dilakukan sampai ukuran fitur lebih besar 
dari \emph{sub-window} dan tidak bisa muat lagi.

Beberapa jenis \textit{feature} yang digunakan adalah 2 persegi horizontal, 
2 persegi vertikal, 4 persegi diagonal, 2 segitiga hadap kiri, 2 segitiga hadap kanan, 
3 persegi horizontal, dan 3 persegi vertikal.

\subsection{Pembuatan \textit{Decision Tree}}

\begin{figure}[H]
  \centering{}
	\includegraphics[width=0.6\textwidth]{gambar/decision\_tree\_1}
  \caption{Contoh sebuah \textit{decision tree} dengan kelas 0, 1, 2 dan 3}
\end{figure} 

Setiap \emph{weak learner} adalah sebuah \emph{decision tree} yang akan mengambil nilai 
dengan fitur untuk digunakan sebagai variabel klasifikasi.
fitur dapat digunakan untuk mencari 
sebuah nilai perbandingan intensitas cahaya dari dua area pada gambar dan 
mendeteksi keberadaan suatu fitur seperti 
perbedaan warna, garis, maupun perbedaan kontras pada gambar.

\textit{Decision tree} pertama akan dibuat dari \textit{root} atau akar, yang lalu 
akan bercabang hingga batas maksimum telah dicapai. \textit{threshold} yang digunakan 
dalam pembuatan \textit{decision tree} adalah salah satu nilai fitur yang dibaca dari gambar. 
Dengan cara ini, \textit{decision tree} tidak perlu mencoba semua nilai yang mungkin, dan 
dengan demikian mempercepat proses pembuatan \textit{decision tree}.
Batas maksimum tinggi \textit{decision tree }yang dipilih adalah tiga 
tingkat, hal ini dikarenakan waktu komputasi yang memakan waktu bila \textit{decision tree} 
memiliki lebih dari 3 tingkat. Di lain sisi, menggunakan tingkat kurang dari tiga tidak mungkin 
memenuhi persyaratan klasifikasi empat kelas.

\subsection{\emph{Boosting}}

\emph{Boosting} ditunjukan untuk memberikan nilai \emph{voting} untuk setiap \textit{weak classifier} 
yang nantinya akan digunakan dalam klasifikasi akhir. Sebelum \emph{boosting} dimulai, 
\textit{weak classifier} yang kurang diskriminatif akan dibuang. Hal ini dilakukan dengan 
membandingkan hasil prediksi \textit{weak classifier} dengan label yang sebenarnya, dimana 
\textit{weak classifier} yang gagal memprediksi 25\% dari set tes akan dibuang. Ini dilakukan 
untuk mengurangi jumlah \textit{weak classifier} yang akan dipakai berikutnya.

Pada tahap ini \textit{boosting} 
akan dijalankan dari \textit{decision tree} yang paling akurat ke yang paling tidak akurat. Penentuan 
akurasi ini dilakukan dengan membandingkan label contoh validasi dengan hasil prediksi setiap \textit{weak classifier}. 
\textit{Weak classifier} yang tidak akurat akan mendapat suara \textit{voting} yang lemah. Rumus untuk mencari 
bobot voting \( \alpha \) dari sebuah \textit{weak classifier} adalah sebagai berikut:

\begin{equation}
  \begin{split}
    \epsilon = \frac{\sum_{i} \text{{image weights}}_i \times \text{{indikator}}_i}{\sum_{i} \text{{image weights}}_i} \\
   \alpha = 0.5 \times \log\left(\frac{1 - \epsilon}{\epsilon + 1e-10}\right) \\
  \end{split}
\end{equation}

\emph{weak classifier} terbaik akan mulai dan 
mengklasifikasi seluruh contoh \emph{dataset} validasi dan mencatat contoh yang 
gagal diklasifikasi oleh \emph{weak classifier} tersebut. Lalu bobot dari contoh tersebut akan 
dinaikan, dengan maksud agar bobot \textit{voting} fitur yang paling akurat akan lebih tinggi daripada 
fitur-fitur yang hanya mendekati menebak. Rumus menaikan bobot:

\begin{equation}
  \text{{image weights}} \times= \exp(\alpha \times \text{{indikator}})
\end{equation}
  
\begin{equation}
  \text{{image weights}} \div= \sum \text{{image weights}}
\end{equation}

\textit{weak classifier} berikutnya lalu akan melakukan prediksi dengan set yang sama, 
namun dengan bobot gambar yang sudah berubah karena \textit{weak classifier}. Sementara 
bobot \textit{voting weak classifier} sebelumnya akan disimpan ke array untuk digunakan nanti. 

Ketika semua \textit{weak learner} sudah dicari bobot \textit{voting}-nya, akan dibandingkan 
akurasi \textit{strong cloassifier} yang dibuat dengan iterasi sebelumnya. Bila didapat bahwa 
ada penurunan akurasi, maupun tidak ada perubahan, maka iterasi Boosting akan disudahi dan 
\textit{strong cloassifier} pada iterasi ini menjadi \textit{final strong classifier}.

\subsection{Pembuatan \emph{Attentional Cascade}}

Karena bobot \textit{voting} dan urutan \textit{weak classifier} sudah ditentukan pada 
tahap \textit{Boosting}, pada tahap ini hanya perlu membagi \textit{weak classifier} menjadi 
beberapa \textit{stage} yang nantinya bisa dipanggil secara terpisah. Sebuah \textit{stage} 
berlaku layaknya sebuah \textit{strong cloassifier} kecil yang ditargetkan hanya memiliki 
tingkat akurasi paling tidak 50\% saja. Hal ini dilakukan agar pendeteksian seluruh \textit{sub-window} 
dapat dilakukan tanpa harus memanggil keseluruhan dari \textit{strong classifier}. 
Metode konstruksi sebuah \textit{stage cascade} adalah sebagai berikut:

\begin{algorithm}
  \caption{Cascade Train Stage}
  \begin{algorithmic}[1]
    \Function{Train\_stage}{}
      \State detection\_rate $\gets$ 0
      \While{detection\_rate $<$ 0.5}
        \If{$\text{len(features)} == 0$}
          \State \textbf{break}
        \EndIf
        \State self.features.append(features)

        \State detection\_rate $\gets$ accuracy\_score()
      \EndWhile
    \EndFunction
  \end{algorithmic}
\end{algorithm}

Nantinya dengan memanggil keseluruhan \textit{cascade} untuk melakukan 
klasifikasi, \textit{stage} dengan satu persatu mengklasifikasi 
\textit{sub-window} yang sedah dicek. Bila sebuah \textit{stage} 
mem-\textit{voting} sebuah \textit{sub-window} sebagai kelas negatif 
(Dalam hal ini voting seluruh \textit{weak classifier} didalam \textit{cascade} 
mengembalikan kelas 0 atau negatif) maka \textit{stage} akan menghentikan 
klasifikasi untuk \textit{sub-window} tersebut dan melanjutkan ke 
\textit{sub-window} berikutnya. Sebaliknya bila \textit{stage} mengembalikan 
kelas selain 0 (1, 2, maupun 3) maka klasifikasi akan dilanjutkan 
untuk \textit{sub-window} tersebut sampai salah satu \textit{stage} lainnya 
mem-\textit{voting} kelas negatif atau semua \textit{stage} habis. 
Dalam situasi habis, \textit{voting} kelas akan mengambil suara dari semua 
\textit{weak classifer} dari semua \textit{stage}.


\section{Skenario Eksperimen dan Validasi}

Tahapan ini adalah penggunakaan \emph{classifier} yang sebenarnya dengan tujuan 
memvalidasi akurasi dari \emph{classifier} tersebut. 
Gambar ikan yang akan dipakai dalam proses validasi akan 
melalui beberapa langkah dalam tahap ini, 
yaitu: \textit{Pre-processing} dalam bentuk \emph{grayscaling}, 
dan deteksi yang sesungguhnya menggunakan \emph{cascade} 
yang telah dibuat dengan metode Sliding Window. Terlebih, klasifikasi akan dilakukan di 
tiga area berbeda pada gambar: area kiri untuk mendeteksi mulut, area tengah untuk mendeteksi sirip, 
dan area kanan untuk mendeteksi ekor. Pada akhirnya ketiga \textit{cascade} 
dari ketiga area tersebut akan mem-\textit{voting} kelas dari objek pada gambar. 
Bila didapat bahwa ketiga \textit{cascade} tersebut mem-\textit{voting} tiga 
kelas yang berbeda, maka kelas yang dipilih adalah 0 atau negatif. 

\subsection{\textit{Pre-processing}}

Untuk klasifikasi sebenarnya, gambar yang akan digunakan 
akan diproses terlebih dahulu. 
Gambar awalnya akan melakui proses \textit{pre-processing} dan dirubah ke dalam warna 
\emph{grayscale}. %(Jelasin perubahan greyscale ini kayak gimana). 
Selain itu resolusi gambar akan dirubah menjadi 350 x 200 piksel untuk mempercepat 
proses klasifikasi.

\subsection{Klasifikasi} 

Pada tahap ini \textit{sliding window} akan mulai bergerak dari pojok kiri atas 
untuk memulai klasifikasi pada area kiri menggunakan \textit{cascade} 
yang sudah dilatih untuk mengklasifikasi mulut ikan. Hal ini dilakukan hingga 
seluruh \textit{sub-window} sudah diklasifikasi dengan hasil negatif, 
atau bila salah satu \textit{sub-window} mengklasfikasi salah satu kelas 
positif. Setelah itu maka klasifikasi pada area tengah atau sirip akan dimulai, dan 
setelahnya baru area kanan atau ekor.

\textit{cascade} bekerja agak berbeda pada klasifikasi sebenarnya. 
Melainkan daripada menhitung nilai intensitas cahaya dan fitur pada semua piksel 
pada gambar, \textit{cascade} hanya menghitung nilai fitur yang berhubungan 
dengan \textit{weak classifier} dalam \textit{stage cascade} sedang 
melakukan klasifikasi.

\begin{algorithm}
  \caption{Final Cascade Classification}
  \begin{algorithmic}[1]
    \Function{FinalCascadeClassification}{$\text{image}, x_{\text{offset}}, y_{\text{offset}}$}
      \State $\text{scoreboard} \gets$ array([0, 0, 0, 0])
      \For{$i$ \textbf{in} range($\text{len}(\text{self.stages})$)}
        \State $\text{stage\_scoreboard} \gets \text{self.stages}[i].\text{stage\_prediction}()$
        \If{$\text{stage\_scoreboard}.\text{argmax}() == 0$} \textbf{break}
        \Else \State $\text{scoreboard} \gets \text{scoreboard} + \text{stage\_scoreboard}$ \EndIf
      \EndFor
      \State \textbf{return} $\text{scoreboard}.\text{argmax}()$
    \EndFunction
  \end{algorithmic}
\end{algorithm}

\begin{algorithm}
  \caption{Stage Prediction}
  \begin{algorithmic}[1]
    \Function{StagePrediction}{$\text{image}, x_{\text{offset}}, y_{\text{offset}}, \text{scoreboard}$}
      \For{$i$ \textbf{in} range($\text{len}(\text{self.features})$)}
        \State $\text{feature\_type}, x, y, \text{width}, \text{height} \gets \text{self.features}[i]$
        \State $x \gets x + x_{\text{offset}}$
        \State $y \gets y + y_{\text{offset}}$
        \State $\text{updated\_feature} \gets (\text{feature\_type}, x, y, \text{width}, \text{height})$
        \State $\text{data\_features} \gets \text{compute\_feature\_with\_matrix}(\text{image}, 0, \text{updated\_feature})$
        \State $\text{prediction} \gets \text{self.trees}[i].\text{predict}(\text{data\_features})$
        \State $\text{scoreboard}[\text{prediction}] \gets \text{scoreboard}[\text{prediction}] + 1 \times \text{self.alpha\_list}[i]$
      \EndFor
      \State \textbf{return} $\text{scoreboard}$
    \EndFunction
  \end{algorithmic}
\end{algorithm}

\begin{figure}[H]
  \centering{}
	\includegraphics[width=0.6\textwidth]{gambar/sliding\_window\_3}
  \caption{titik awal \textit{sliding window} (kotak hijau) dan titik akhir (kotak kuning)}
\end{figure}

\subsection{Anotasi}

\begin{figure}[H]
  \centering{}
	\includegraphics[width=0.4\textwidth]{gambar/sliding\_window\_2}
  \caption{Gambaran \textit{sub-window} yang berhasil mengklasifikasi ikan didalam gambar}
\end{figure}

Setelah semua \textit{sub-window} sudah diklasifikasi dengan menggunakan 
\emph{strong classifier}. Algoritma akan menggambarkan di lokasi \textit{sub-window} 
yang positif terklasifikasi (Memiliki salah satu kelas ikan yang telah dilatih ke \emph{strong classifier}), 
\emph{bounding box} untuk menganotasi kelasnya. Pengguna lalu dapat menentukan 
dari hasil anotasi bilamana target akurasi sudah tercapai.


